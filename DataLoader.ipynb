{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74f1222c",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644a2fc4",
   "metadata": {},
   "source": [
    "The DataLoader is an iterator. At each iteration, it yields a batch of training examples from a dataset. It stops when it exhausts the training examples in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59997d3f",
   "metadata": {},
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f069c4c1",
   "metadata": {},
   "source": [
    "It takes as input:\n",
    "* dataset: A dictionary-like object that we can use to look up a training example by key. This look up typically requires reading data from disk (I/O) and processing that data (compute).\n",
    "* batch_size: The number of training examples in each batch (except maybe the last batch).\n",
    "* shuffle: If True, then randomly sample a batch without replacement at each iteration. Otherwise, sample each batch preserving the order of the training examples in the dataset.\n",
    "* collate_fn: A function that takes a list of training examples as input and outputs a batch.\n",
    "* num_workers: If 0, then just use the single main process to prepare each batch. Otherwise, use `num_workers` concurrent workers to prepare batches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbef586",
   "metadata": {},
   "source": [
    "We define a Dataset class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d5ce44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class Dataset:\n",
    "    \n",
    "    def __init__(self, features, labels):\n",
    "        self.examples = list(zip(features, labels))\n",
    "       \n",
    "    def __getitem__(self, i):\n",
    "        time.sleep(0.1) # simulate work\n",
    "        return self.examples[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7112ae",
   "metadata": {},
   "source": [
    "We also define a collate_fn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b25e4a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(examples):\n",
    "    \"\"\"[(x1,y1),...,(xn,yn)] -> X, y\"\"\"\n",
    "    z = list(zip(*examples))\n",
    "    data = np.stack(z[0], axis=0)\n",
    "    target = np.stack(z[1], axis=0)\n",
    "    return (data, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bb6a87",
   "metadata": {},
   "source": [
    "## Single process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62fbb63",
   "metadata": {},
   "source": [
    "\n",
    "When `num_workers` == 0, the implementation is relatively straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb30ceed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def _process_batch_idxs(batch_idxs, dataset, collate_fn):\n",
    "    return collate_fn([dataset[idx] for idx in batch_idxs])\n",
    "\n",
    "class SingleProcessDataLoader:\n",
    "\n",
    "    def __init__(self, dataset, batch_size, shuffle, collate_fn, num_workers=0):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.collate_fn = collate_fn\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        num_examples = len(self.dataset)\n",
    "        self.num_remaining_examples = num_examples\n",
    "        \n",
    "        if shuffle:\n",
    "            self.sampler = iter(np.random.permutation(num_examples))\n",
    "        else:\n",
    "            self.sampler = iter(range(num_examples))            \n",
    "\n",
    "    def __iter__(self):\n",
    "        # PyTorch's DataLoader will restart\n",
    "        # every time you use it in a new loop.[1,2]\n",
    "        # E.g., the first and second loops will yield\n",
    "        # the same batches:\n",
    "        #\n",
    "        # dataloader = DataLoader(...)\n",
    "        # for batch in dataloader:\n",
    "        #    ...\n",
    "        # for batch in dataloader:\n",
    "        #    ...\n",
    "        #\n",
    "        # This is not the case for e.g. the code below:\n",
    "        #\n",
    "        # it = iter(range(10))\n",
    "        # for entry in it:\n",
    "        #   ...\n",
    "        # for entry in it:\n",
    "        #   ...\n",
    "        #\n",
    "        # If we do not break out of the first\n",
    "        # loop early, then the second loop will\n",
    "        # immediately break, because the iterator\n",
    "        # will be exhausted.\n",
    "        #\n",
    "        # We implement the behavior of iter(range(10)).\n",
    "        # In order to implement PyTorch's behavior,\n",
    "        # we would move most of the logic of the class\n",
    "        # to DataLoaderIter and replace \"self\" here\n",
    "        # with \"DataLoaderIter(self)\".\n",
    "        #\n",
    "        # [1]: https://stackoverflow.com/questions/60311307/how-does-one-reset-the-dataloader-in-pytorch\n",
    "        # [2]: \"When __iter__ is a generator it's returned as a new closure every time. \n",
    "        #       It'd be the best not to modify the internal state (i.e. assign to self),\n",
    "        #       but to have these as local variables. Now, if you start iterating over the dataloader,\n",
    "        #       stop in the middle, take a new iterator, and continue iterating over the first one,\n",
    "        #       you'll start from the beginning.\"\n",
    "        #      (https://github.com/pytorch/pytorch/pull/44/commits/\\\n",
    "        #       55afe5137eb57d27de76208827652dfc192896df#discussion_r79853797)\n",
    "        return self\n",
    "    \n",
    "    def _next_batch_idxs(self):\n",
    "        # Note that the `next` call can raise a StopIteration\n",
    "        # and stop the `self` iterator, but it shouldn't happen\n",
    "        # in practice, because sampler is the size of the dataset\n",
    "        # and we keep track of self.num_remaining_examples.\n",
    "        n = min(self.num_remaining_examples, self.batch_size)\n",
    "        batch_idxs = [next(self.sampler) for _ in range(n)]\n",
    "        self.num_remaining_examples -= len(batch_idxs)\n",
    "        return batch_idxs\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self.num_workers == 0:\n",
    "            if self.num_remaining_examples == 0:\n",
    "                raise StopIteration\n",
    "            batch_idxs = self._next_batch_idxs()\n",
    "            batch = _process_batch_idxs(batch_idxs, self.dataset, self.collate_fn)\n",
    "            return batch\n",
    "            \n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b0b7ff",
   "metadata": {},
   "source": [
    "Here's the basic usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40eaa379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "n = 20\n",
    "features = np.random.randn(n, 100)\n",
    "labels = np.random.permutation(n)\n",
    "dataset = Dataset(features, labels)\n",
    "dataloader = SingleProcessDataLoader(dataset, batch_size=2, shuffle=False, collate_fn=collate_fn)\n",
    "for i, (X, y) in enumerate(dataloader):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39750cf1",
   "metadata": {},
   "source": [
    "## Multiple processes (out-of-order)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3108b9",
   "metadata": {},
   "source": [
    "Implementing the multiprocess version is a trickier.\n",
    "\n",
    "The idea is to create multiple child processes, where each child process is a worker that continuously tries to get a batch of indices from an input queue. Once it gets a batch of indices, it looks up the training example for each index using the dataset and then collates those training examples to construct a batch. It puts this batch onto an output queue. It only exits when it gets an exit signal from the input queue instead of a batch of indices.\n",
    "\n",
    "At each iteration, the parent process puts a batch of indices on the input queue (provided there are training examples remaining) and then gets a batch from the output queue to return at that iteration.\n",
    "\n",
    "Every time it puts a batch of indices on the input queue, it increments a counter by 1. Every time it gets a batch from the output queue, it decrements the counter by 1. In this way, the value of the counter at the end of the iteration is the same as the value of the counter at the start of the iteration unless we have exhausted the remaining training examples. If we have exhausted the remaining training examples, then the value of the counter at the end of the iteration is 1 less than the value of the counter at the start of the iteration. \n",
    "\n",
    "We place at least one batch of indices on the input queue before any of the child processes are created, so the counter is positive at the start of the first iteration. Eventually, we exhaust the training examples and the counter decrements by 1 at each iteration until it hits 0. When it hits 0, we know that we have processed all the batches and we can send the exit signal to all the workers and raise a StopIteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d040db37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: multiprocess in /Users/jakemarcus/opt/anaconda3/lib/python3.9/site-packages (0.70.14)\r\n",
      "Requirement already satisfied: dill>=0.3.6 in /Users/jakemarcus/opt/anaconda3/lib/python3.9/site-packages (from multiprocess) (0.3.6)\r\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/41385708/multiprocessing-example-giving-attributeerror\n",
    "!pip install multiprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "590ef5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import multiprocess as multiprocessing\n",
    "\n",
    "def _process_batch_idxs(batch_idxs, dataset, collate_fn):\n",
    "    return collate_fn([dataset[idx] for idx in batch_idxs])\n",
    "\n",
    "def _worker(dataset, input_queue, output_queue, collate_fn):\n",
    "    while True:\n",
    "        batch_idxs = input_queue.get()\n",
    "        \n",
    "        if batch_idxs is None:\n",
    "            break\n",
    "            \n",
    "        batch = _process_batch_idxs(batch_idxs, dataset, collate_fn)\n",
    "        \n",
    "        output_queue.put(batch)\n",
    "\n",
    "class OutOfOrderDataLoader:\n",
    "\n",
    "    def __init__(self, dataset, batch_size, shuffle, collate_fn, num_workers=0):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.collate_fn = collate_fn\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        num_examples = len(self.dataset)\n",
    "        self.num_remaining_examples = num_examples\n",
    "        \n",
    "        if shuffle:\n",
    "            self.sampler = iter(np.random.permutation(num_examples))\n",
    "        else:\n",
    "            self.sampler = iter(range(num_examples))\n",
    "\n",
    "        self.unfinished_tasks = 0\n",
    "        self.all_tasks_done = False\n",
    "        self.workers = []\n",
    "            \n",
    "        if num_workers > 0:\n",
    "            self.input_queue = multiprocessing.Queue()\n",
    "            self.output_queue = multiprocessing.Queue()\n",
    "            \n",
    "            # We start by putting at least 1 batch of indices on\n",
    "            # the `input_queue`. This increments `unfinished_tasks`.\n",
    "            # We also want to avoid idle workers by adding multiple\n",
    "            # batches to the input queue before the workers start.\n",
    "            # Adding some multiple of `num_workers` would also\n",
    "            # work.\n",
    "            for _ in range(num_workers):\n",
    "                self._put_batch_idxs()\n",
    "                \n",
    "            for _ in range(num_workers):\n",
    "                w = multiprocessing.Process(\n",
    "                    target=_worker,\n",
    "                    args=(\n",
    "                        self.dataset,\n",
    "                        self.input_queue,\n",
    "                        self.output_queue,\n",
    "                        self.collate_fn),\n",
    "                    daemon=True)\n",
    "                w.start()\n",
    "                self.workers.append(w)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def _next_batch_idxs(self):\n",
    "        n = min(self.num_remaining_examples, self.batch_size)\n",
    "        batch_idxs = [next(self.sampler) for _ in range(n)]\n",
    "        self.num_remaining_examples -= len(batch_idxs)\n",
    "        return batch_idxs\n",
    "    \n",
    "    def _put_batch_idxs(self):\n",
    "        if self.num_remaining_examples == 0:\n",
    "            return\n",
    "        batch_idxs = self._next_batch_idxs()\n",
    "        self.input_queue.put(batch_idxs)\n",
    "        self.unfinished_tasks += 1\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self.num_workers == 0:\n",
    "            if self.num_remaining_examples == 0:\n",
    "                raise StopIteration\n",
    "            batch_idxs = self._next_batch_idxs()\n",
    "            return _process_batch_idxs(batch_idxs, self.dataset, self.collate_fn)\n",
    "            \n",
    "        if self.unfinished_tasks == 0:\n",
    "            self._join()\n",
    "            raise StopIteration\n",
    "            \n",
    "        self._put_batch_idxs()\n",
    "        batch = self.output_queue.get()\n",
    "        self.unfinished_tasks -= 1\n",
    "        \n",
    "        return batch\n",
    "    \n",
    "    def _join(self):\n",
    "        if self.all_tasks_done:\n",
    "            return\n",
    "        for _ in range(len(self.workers)):\n",
    "            self.input_queue.put(None)\n",
    "        for w in self.workers:\n",
    "            w.join()\n",
    "        self.all_tasks_done = True\n",
    "            \n",
    "    def __del__(self):\n",
    "        self._join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6270b246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "dataloader = OutOfOrderDataLoader(dataset, batch_size=2, shuffle=False, collate_fn=collate_fn, num_workers=4)\n",
    "for i, (X, y) in enumerate(dataloader):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b66bd91",
   "metadata": {},
   "source": [
    "## Multiple processes (in-order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa5c1142",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import multiprocess as multiprocessing\n",
    "\n",
    "\n",
    "class Dataset:\n",
    "    \n",
    "    def __init__(self, features, labels):\n",
    "        self.examples = list(zip(features, labels))\n",
    "       \n",
    "    def __getitem__(self, i):\n",
    "        time.sleep(0.1) # simulate work\n",
    "        return self.examples[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "\n",
    "def collate_fn(examples):\n",
    "    \"\"\"[(x1,y1),...,(xn,yn)] -> X, y\"\"\"\n",
    "    z = list(zip(*examples))\n",
    "    data = np.stack(z[0], axis=0)\n",
    "    target = np.stack(z[1], axis=0)\n",
    "    return (data, target)\n",
    "\n",
    "\n",
    "def _process_batch_idxs(batch_idxs, dataset, collate_fn):\n",
    "    return collate_fn([dataset[idx] for idx in batch_idxs])\n",
    "\n",
    "\n",
    "def _worker(dataset, input_queue, output_queue, collate_fn):\n",
    "    while True:\n",
    "        r = input_queue.get()\n",
    "\n",
    "        if r is None:\n",
    "            break\n",
    "\n",
    "        idx, batch_idxs = r\n",
    "\n",
    "        batch = _process_batch_idxs(batch_idxs, dataset, collate_fn)\n",
    "        output_queue.put((idx, batch))\n",
    "\n",
    "\n",
    "class DataLoader:\n",
    "\n",
    "    def __init__(self, dataset, batch_size=1, shuffle=False, collate_fn=collate_fn, num_workers=0):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.collate_fn = collate_fn\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        n_examples = len(self.dataset)\n",
    "\n",
    "        if shuffle:\n",
    "            self.sampler = iter(np.random.permutation(n_examples))\n",
    "        else:\n",
    "            self.sampler = iter(range(n_examples))\n",
    "\n",
    "        self.n_remaining_examples = n_examples\n",
    "        self.unfinished_tasks = 0\n",
    "        self.all_tasks_done = False\n",
    "        self.workers = []\n",
    "\n",
    "        if num_workers > 0:\n",
    "            self.input_queue = multiprocessing.Queue()\n",
    "            self.output_queue = multiprocessing.Queue()\n",
    "\n",
    "            # Every time we put an item in `input_queue`,\n",
    "            # we increment `send_idx`. This tracks the \n",
    "            # order in which we put items in the `input_queue`\n",
    "            # in the main process.\n",
    "            self.send_idx = 0\n",
    "\n",
    "            # Every time we return a batch, we increment\n",
    "            # `recv_idx`.\n",
    "            self.recv_idx = 0\n",
    "\n",
    "            self.cache = {}\n",
    "\n",
    "            for _ in range(self.num_workers):\n",
    "                self._put_batch_idxs()\n",
    "\n",
    "            for _ in range(self.num_workers):\n",
    "                w = multiprocessing.Process(\n",
    "                    target=_worker,\n",
    "                    args=(self.dataset, self.input_queue, self.output_queue, self.collate_fn),\n",
    "                    daemon=True)\n",
    "                w.start()\n",
    "                self.workers.append(w)\n",
    "\n",
    "    def _next_batch_idxs(self):\n",
    "        n = min(self.n_remaining_examples, self.batch_size)\n",
    "        batch_idxs = [next(self.sampler) for _ in range(n)]\n",
    "        self.n_remaining_examples -= len(batch_idxs)\n",
    "        return batch_idxs\n",
    "\n",
    "    def _put_batch_idxs(self):\n",
    "        if self.n_remaining_examples == 0:\n",
    "            return\n",
    "        batch_idxs = self._next_batch_idxs()\n",
    "        self.input_queue.put((self.send_idx, batch_idxs))\n",
    "        self.unfinished_tasks += 1\n",
    "        self.send_idx += 1\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.num_workers == 0:\n",
    "            if self.n_remaining_examples == 0:\n",
    "                raise StopIteration\n",
    "            batch_idxs = self._next_batch_idxs()\n",
    "            return _process_batch_idxs(batch_idxs, self.dataset, self.collate_fn)\n",
    "\n",
    "        if self.recv_idx in self.cache:\n",
    "            batch = self.cache.pop(self.recv_idx)\n",
    "            self.recv_idx += 1\n",
    "            return batch\n",
    "\n",
    "        # Should check after checking the cache\n",
    "        # to make the sure the cache is empty.\n",
    "        if self.unfinished_tasks == 0:\n",
    "            self._join_workers()\n",
    "            raise StopIteration\n",
    "\n",
    "        while True:\n",
    "            self._put_batch_idxs()\n",
    "            idx, batch = self.output_queue.get()\n",
    "            self.unfinished_tasks -= 1\n",
    "\n",
    "            if idx != self.recv_idx:\n",
    "                self.cache[idx] = batch\n",
    "                continue\n",
    "\n",
    "            self.recv_idx += 1\n",
    "            return batch\n",
    "\n",
    "    def _join_workers(self):\n",
    "        if self.all_tasks_done:\n",
    "            return\n",
    "        self.all_tasks_done = True\n",
    "        for _ in range(len(self.workers)):\n",
    "            self.input_queue.put(None)\n",
    "        for w in self.workers:\n",
    "            w.join()\n",
    "\n",
    "    def __del__(self):\n",
    "        if self.all_tasks_done:\n",
    "            return\n",
    "        self._join_workers()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f5a1ef",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3d1017f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import math\n",
    "import sys\n",
    "import traceback\n",
    "\n",
    "class ErrorDataset:\n",
    "\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "class TestDataLoader(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        n = 20\n",
    "        np.random.seed(0)\n",
    "        self.data = np.random.randn(n, 2, 3, 5)\n",
    "        self.labels = np.array(np.random.permutation(n // 2).tolist() * 2)\n",
    "        self.dataset = Dataset(self.data, self.labels)\n",
    "\n",
    "    def _test_sequential(self, loader):\n",
    "        batch_size = loader.batch_size\n",
    "        i = 0\n",
    "        for i, (sample, target) in enumerate(loader):\n",
    "            idx = i * batch_size\n",
    "            np.testing.assert_almost_equal(sample, self.data[idx:idx+batch_size])\n",
    "            np.testing.assert_almost_equal(target, self.labels[idx:idx+batch_size])\n",
    "        self.assertEqual(i, math.floor((len(self.dataset)-1) / batch_size))\n",
    "\n",
    "    def _test_shuffle(self, loader):\n",
    "        found_data = {i: 0 for i in range(self.data.shape[0])}\n",
    "        found_labels = {i: 0 for i in range(self.labels.shape[0])}\n",
    "        batch_size = loader.batch_size\n",
    "        for i, (batch_samples, batch_targets) in enumerate(loader):\n",
    "            for sample, target in zip(batch_samples, batch_targets):\n",
    "                for data_point_idx, data_point in enumerate(self.data):\n",
    "                    if (data_point == sample).all():\n",
    "                        self.assertFalse(found_data[data_point_idx])\n",
    "                        found_data[data_point_idx] += 1\n",
    "                        break\n",
    "                self.assertEqual(target, self.labels[data_point_idx:(data_point_idx + 1)])\n",
    "                found_labels[data_point_idx] += 1\n",
    "            self.assertEqual(sum(found_data.values()), (i+1) * batch_size)\n",
    "            self.assertEqual(sum(found_labels.values()), (i+1) * batch_size)\n",
    "        self.assertEqual(i, math.floor((len(self.dataset)-1) / batch_size))\n",
    "\n",
    "    def _test_error(self, loader):\n",
    "        it = iter(loader)\n",
    "        errors = 0\n",
    "        while True:\n",
    "            try:\n",
    "                it.next()\n",
    "            except NotImplementedError:\n",
    "                msg = \"\".join(traceback.format_exception(*sys.exc_info()))\n",
    "                self.assertTrue(\"collate_fn\" in msg)\n",
    "                errors += 1\n",
    "            except StopIteration:\n",
    "                self.assertEqual(errors,\n",
    "                    math.ceil(float(len(loader.dataset))/loader.batch_size))\n",
    "                return\n",
    "\n",
    "    def test_sequential(self):\n",
    "        self._test_sequential(DataLoader(self.dataset))\n",
    "\n",
    "    def test_sequential_batch(self):\n",
    "        self._test_sequential(DataLoader(self.dataset, batch_size=2))\n",
    "\n",
    "    def test_shuffle(self):\n",
    "        self._test_shuffle(DataLoader(self.dataset, shuffle=True))\n",
    "\n",
    "    def test_shuffle_batch(self):\n",
    "        self._test_shuffle(DataLoader(self.dataset, batch_size=2, shuffle=True))\n",
    "\n",
    "    def test_sequential_workers(self):\n",
    "        self._test_sequential(DataLoader(self.dataset, num_workers=4))\n",
    "\n",
    "    def test_sequential_batch_workers(self):\n",
    "        self._test_sequential(DataLoader(self.dataset, batch_size=2, num_workers=4))\n",
    "\n",
    "    def test_shuffle_workers(self):\n",
    "        self._test_shuffle(DataLoader(self.dataset, shuffle=True, num_workers=4))\n",
    "\n",
    "    def test_shuffle_batch_workers(self):\n",
    "        self._test_shuffle(DataLoader(self.dataset, batch_size=2, shuffle=True, num_workers=4))\n",
    "\n",
    "    def test_partial_workers(self):\n",
    "        \"check that workers exit even if the iterator is not exhausted\"\n",
    "        loader = iter(DataLoader(self.dataset, batch_size=2, num_workers=4))\n",
    "        workers = loader.workers\n",
    "        for i, sample in enumerate(loader):\n",
    "            if i == 3:\n",
    "                break\n",
    "        del loader\n",
    "        for w in workers:\n",
    "            w.join(1.0)  # timeout of one second\n",
    "            self.assertFalse(w.is_alive(), 'subprocess not terminated')\n",
    "            self.assertEqual(w.exitcode, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a961bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_partial_workers (__main__.TestDataLoader)\n",
      "check that workers exit even if the iterator is not exhausted ... ok\n",
      "test_sequential (__main__.TestDataLoader) ... ok\n",
      "test_sequential_batch (__main__.TestDataLoader) ... ok\n",
      "test_sequential_batch_workers (__main__.TestDataLoader) ... ok\n",
      "test_sequential_workers (__main__.TestDataLoader) ... ok\n",
      "test_shuffle (__main__.TestDataLoader) ... ok\n",
      "test_shuffle_batch (__main__.TestDataLoader) ... ok\n",
      "test_shuffle_batch_workers (__main__.TestDataLoader) ... ok\n",
      "test_shuffle_workers (__main__.TestDataLoader) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 9 tests in 11.336s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7f79500ff370>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f14cace",
   "metadata": {},
   "source": [
    "## Sources\n",
    "\n",
    "* \"History for pytorch/torch/utils/data/dataloader.py\" [(link)](https://github.com/pytorch/pytorch/commits/master?after=7dd7dde0332c6582082c9a5475d25668652db83d+139&branch=master&path%5B%5D=torch&path%5B%5D=utils&path%5B%5D=data&path%5B%5D=dataloader.py&qualified_name=refs%2Fheads%2Fmaster)\n",
    "* \"Add multiprocess data loader + improvements to torch.utils.data\"\n",
    "    * https://github.com/pytorch/pytorch/pull/44\n",
    "    * https://github.com/pytorch/pytorch/commit/a1f5fe6a8f47ddb3d79c8492e248762883e80214\n",
    "    * https://github.com/pytorch/pytorch/blob/a1f5fe6a8f47ddb3d79c8492e248762883e80214/torch/utils/data/dataloader.py\n",
    "    * https://github.com/pytorch/pytorch/blob/a1f5fe6a8f47ddb3d79c8492e248762883e80214/test/test_utils.py\n",
    "* \"Make DataLoader preserve the ordering of the dataset\"\n",
    "    * https://github.com/pytorch/pytorch/pull/135\n",
    "    * https://github.com/pytorch/pytorch/commit/6db721b5dda11638aa2eaf6aaea3af341274ef21\n",
    "    * https://github.com/pytorch/pytorch/blob/6db721b5dda11638aa2eaf6aaea3af341274ef21/torch/utils/data/dataloader.py\n",
    "    * https://github.com/pytorch/pytorch/blob/6db721b5dda11638aa2eaf6aaea3af341274ef21/test/test_dataloader.py\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
