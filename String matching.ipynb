{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f4aa063",
   "metadata": {},
   "source": [
    "# String matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31242b35",
   "metadata": {},
   "source": [
    "Given a `txt` string and a `pat` string, return a list of all the start indices for matches to `pat` in `txt`.\n",
    "\n",
    "For example:\n",
    "\n",
    "```\n",
    "txt = \"AABAACAADAABAABA\"\n",
    "pat = \"AABA\"\n",
    "# 0  1  2  3  4  5  6  7  8  9  10  11  12  13  14  15\n",
    "# A  A  B  A  A  C  A  A  D  A  A   B   A   A   B   A\n",
    "# |--------|\n",
    "#                            |----------|\n",
    "#                                       |----------|\n",
    "\n",
    "assert search(txt, pat) == [0,9,12]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bf0026",
   "metadata": {},
   "source": [
    "## Naive string matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3669fa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_search(txt, pat):\n",
    "    n = len(txt)\n",
    "    m = len(pat)\n",
    "    matches = []\n",
    "    for i in range(0, n - m + 1):\n",
    "        is_match = True\n",
    "        for j in range(len(pat)):\n",
    "            if i+j >= len(txt) or pat[j] != txt[i+j]:\n",
    "                is_match = False\n",
    "                break\n",
    "        if is_match:\n",
    "            matches.append(i)\n",
    "    return matches\n",
    "\n",
    "assert naive_search(\"AABAACAADAABAABA\", \"AABA\") == [0,9,12]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2d233e",
   "metadata": {},
   "source": [
    "This solution has O((n-m+1)m) worst case time complexity, where n is the length of `txt` and m is the length of `pat`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbad0e5",
   "metadata": {},
   "source": [
    "## Rabin-Karp algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5d2ca9",
   "metadata": {},
   "source": [
    "The idea of the Rabin-Harp algorithm is to precompute the hash value for `pat` and then compute a rolling hash value for each window of text the same length as `pat` in `txt`. The next hash value in the rolling hash can be efficiently computed by modifying the last hash value rather than computing it from scratch each step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dc9a06",
   "metadata": {},
   "source": [
    "The implementation below is based on the following implementations:\n",
    "\n",
    "1. http://web.archive.org/web/20230124203901/https://github.com/hansrajdas/algorithms/blob/master/Level-3/rabin_karp.py\n",
    "2. http://web.archive.org/web/20221208004703/http://www-igm.univ-mlv.fr/~lecroq/string/node5.html\n",
    "3. http://web.archive.org/web/20230124001119/https://algs4.cs.princeton.edu/53substring/RabinKarp.java.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d4976747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the value of INT_MAX in C as the large\n",
    "# prime number following implementation #2.\n",
    "# 2**31 - 1 = 2147483647, which is prime.\n",
    "q = 2**31 - 1\n",
    "\n",
    "# The number of bits in the extended ASCII\n",
    "# character set.\n",
    "R = 256\n",
    "\n",
    "def _hash(key, m):\n",
    "    \"\"\"Compute hash for key[:m]\n",
    "    \n",
    "    In particular:\n",
    "    1) convert each character in key[:m] to its ASCII value\n",
    "    2) convert those ASCII values to an integer in base-R,\n",
    "       where R is the number of bits in the ASCII character set.\n",
    "    3) take the integer modulo q to keep the hash value small and avoid\n",
    "       integer overflow (not typically a problem in Python, but\n",
    "       we leave it for educational purposes).\n",
    "    \"\"\"\n",
    "    # Use Horner's method to evaluate the polynomial that\n",
    "    # corresponds to the hash value in linear time.\n",
    "    h = 0\n",
    "    for j in range(m):\n",
    "        h = (R*h + ord(key[j])) % q\n",
    "    return h\n",
    "        \n",
    "def _check(txt, pat, i):\n",
    "    for j in range(len(pat)):\n",
    "        if pat[j] != txt[i + j]:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "class RabinKarp:\n",
    "    \n",
    "    def __init__(self, pat):\n",
    "        self.pat = pat\n",
    "        m = len(pat)\n",
    "            \n",
    "        # precompute R**(m-1) % q for use in removing leading digit\n",
    "        RM = 1\n",
    "        for i in range(1, m):\n",
    "            RM = (R * RM) % q\n",
    "        self.RM = RM\n",
    "        self.patHash = _hash(pat, m)\n",
    "\n",
    "    def search(self, txt):\n",
    "        n = len(txt)\n",
    "        m = len(self.pat)\n",
    "        \n",
    "        matches = []\n",
    "        if n < m:\n",
    "            return matches\n",
    "\n",
    "        txtHash = _hash(txt, m)\n",
    "\n",
    "        if (self.patHash == txtHash) and _check(txt, self.pat, 0):\n",
    "            matches.append(0)\n",
    "        \n",
    "        for i in range(m, n):\n",
    "            # Compute the rolling hash.\n",
    "            txtHash = (txtHash + q - self.RM*ord(txt[i-m]) % q) % q\n",
    "            txtHash = (txtHash*R + ord(txt[i])) % q\n",
    "            \n",
    "            offset = i - m + 1\n",
    "            if (self.patHash == txtHash) and _check(txt, self.pat, offset):\n",
    "                matches.append(offset)\n",
    "        \n",
    "        return matches\n",
    "\n",
    "assert RabinKarp(\"AABA\").search(\"AABAACAADAABAABA\") == [0,9,12]\n",
    "assert RabinKarp(\"TEST\").search(\"THIS IS A TEST TEXT\") == [10]\n",
    "assert RabinKarp(\"AAAA\").search(\"AAAAABAAABA\") == [0, 1]\n",
    "assert RabinKarp(\"ABABCABAB\").search(\"ABABDABACDABABCABAB\") == [10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1263d3c5",
   "metadata": {},
   "source": [
    "This solution has O(m) worse case time complexity for preprocessing and O((n-m+1)m) worst case time complexity for the search, where n is the length of `txt` and m is the length of `pat`. Under reasonable assumptions, the expected time complexity for the matching is O(n) (see section 32.2 of CLRS for details)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8010da88",
   "metadata": {},
   "source": [
    "## Finite automata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843fbf1c",
   "metadata": {},
   "source": [
    "This implementation is based on section 32.3 of CLRS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e88ac7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_transition_function(pat, vocab):\n",
    "    m = len(pat)\n",
    "    v = len(vocab)\n",
    "    delta = [[None for _ in range(v)] for _ in range(m + 1)]\n",
    "    for q in range(m + 1):\n",
    "        for i, ch in enumerate(vocab):\n",
    "            # delta[q][i] gives the next state if\n",
    "            # we're in state q and we have just read character ch,\n",
    "            # In other words, it means that we have read pat[:q] and\n",
    "            # then ch.\n",
    "            #\n",
    "            # ... pat[0] pat[1] ... pat[q] ch ...\n",
    "            #                              ^\n",
    "            #                          we're here\n",
    "            #\n",
    "            # The next state is the length of the longest prefix of\n",
    "            # pat that matches a suffix of pat[:q] + ch.\n",
    "            #\n",
    "            # If q < m and ch == pat[q+1], then the longest\n",
    "            # prefix is pat[:q+1], which gives us a next state of q+1,\n",
    "            # which means we just move forward a state.\n",
    "            # \n",
    "            # Otherwise, we move backward some number of states.\n",
    "            # For example, suppose the pattern is \"ababaca\"\n",
    "            # (Figure 32.7 in CLRS). And suppose we're here:\n",
    "            #\n",
    "            # ...ababac...\n",
    "            #         ^\n",
    "            # At this step, q = 5. Then, we read 'b'. The longest\n",
    "            # prefix of pat that matches a suffix of \"ababab\" is\n",
    "            # \"abab\". The length of that prefix is 4, so we move\n",
    "            # back to state 4. This is moving backward the least\n",
    "            # number of states possible.\n",
    "            \n",
    "            # CLRS uses min(m + 1, q + 2), but\n",
    "            # min(m, q + 1) gives the same transition matrix\n",
    "            # as Figure 32.7b. CLRS also states in the paragraph\n",
    "            # below the algorithm that \"The code starts with the\n",
    "            # largest conceivable value of k, which is min(m, q+1).\"\n",
    "            k = min(m, q + 1) \n",
    "            while k > 0 and (not (pat[:q] + ch).endswith(pat[:k])):\n",
    "                k -=1\n",
    "            delta[q][i] = k\n",
    "    return delta\n",
    "\n",
    "vocab = [\"a\", \"b\", \"c\"]\n",
    "pat = \"ababaca\"\n",
    "delta = compute_transition_function(pat, vocab)\n",
    "expected = [\n",
    "    [1, 0, 0],\n",
    "    [1, 2, 0],\n",
    "    [3, 0, 0],\n",
    "    [1, 4, 0],\n",
    "    [5, 0, 0],\n",
    "    [1, 4, 6],\n",
    "    [7, 0, 0],\n",
    "    [1, 2, 0]]\n",
    "assert delta == expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fe84bb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finite_automaton_search(txt, delta, m, ch_to_idx):\n",
    "    n = len(txt)\n",
    "    q = 0\n",
    "    matches = []\n",
    "    for i in range(n):\n",
    "        j = ch_to_idx[txt[i]]\n",
    "        q = delta[q][j]\n",
    "        if q == m:\n",
    "            matches.append(i-m+1)\n",
    "    return matches\n",
    "\n",
    "txt = \"AABAACAADAABAABA\"\n",
    "pat = \"AABA\"\n",
    "m = len(pat)\n",
    "vocab = [\"A\", \"B\", \"C\", \"D\"]\n",
    "ch_to_idx = {ch: idx for idx, ch in enumerate(vocab)}\n",
    "delta = compute_transition_function(pat, vocab)\n",
    "m = len(pat)\n",
    "assert finite_automaton_search(txt, delta, m, ch_to_idx) == [0, 9, 12]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8d7e18",
   "metadata": {},
   "source": [
    "The worst case time complexity of the preprocessing step in this solution is O(m^3 |vocab|) though it can be improved to O(m|vocab|) (see exercises 32.4-32.8 in CLRS). The worst case time complexity for the search is O(n)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b0850f",
   "metadata": {},
   "source": [
    "## Knuth-Morris-Pratt algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4de46bf",
   "metadata": {},
   "source": [
    "The implementation below is based on the [CLRS implementation](http://web.archive.org/web/20230125153025/https://algs4.cs.princeton.edu/53substring/KMP.java.html) in Java. It only finds the first occurrence of the pattern rather than all occurrences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "789dcc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of bits in the extended ASCII\n",
    "# character set.\n",
    "R = 256\n",
    "\n",
    "class KMP:\n",
    "    \n",
    "    def __init__(self, pat):\n",
    "        m = len(pat)\n",
    "        dfa = [[0 for _ in range(m)] for _ in range(R)]\n",
    "        dfa[ord(pat[0])][0] = 1\n",
    "        x = 0\n",
    "        for j in range(1, m):\n",
    "            for c in range(R):\n",
    "                dfa[c][j] = dfa[c][x]\n",
    "            dfa[ord(pat[j])][j] = j + 1\n",
    "            x = dfa[ord(pat[j])][x]\n",
    "        self.dfa = dfa\n",
    "        \n",
    "    def search(self, txt):\n",
    "        matches = []\n",
    "        n = len(txt)\n",
    "        m = len(self.dfa[0])\n",
    "        i = j = 0\n",
    "        while i < n and j < m:\n",
    "            j = self.dfa[ord(txt[i])][j]\n",
    "            i += 1\n",
    "        if j == m:\n",
    "            return i - m\n",
    "        return n\n",
    "\n",
    "assert KMP(\"AABA\").search(\"AABAACAADAABAABA\") == 0\n",
    "assert KMP(\"TEST\").search(\"THIS IS A TEST TEXT\") == 10\n",
    "assert KMP(\"AAAA\").search(\"AAAAABAAABA\") == 0\n",
    "assert KMP(\"ABABCABAB\").search(\"ABABDABACDABABCABAB\") == 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8646e54d",
   "metadata": {},
   "source": [
    "This solution has O(mR) worse case time complexity for preprocessing and O(n) worst case time complexity for the search. It also takes O(mR) space. An [improved version](http://web.archive.org/web/20230124195827/https://algs4.cs.princeton.edu/53substring/KMPplus.java.html) takes O(m) time for preprocessing and O(n) time for search, i.e. is independent of the vocab size/radix R, but \"it's sufficiently more complicated that you should be prepared to study it carefully to really understand it\" (Princeton KMP (Knuth Morris Pratt) Algorithm)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd44095c",
   "metadata": {},
   "source": [
    "## Sources\n",
    "\n",
    "* Chapter 32, \"String matching\", CLRS\n",
    "* \"[This website](http://www-igm.univ-mlv.fr/~lecroq/string/) is a great resource for exact string searching algorithms\" (http://web.archive.org/web/20230124195819/https://algs4.cs.princeton.edu/53substring/)\n",
    "* [43 5 Rabin Karp](https://www.youtube.com/watch?v=3KXsyZFHidk)\n",
    "* [COMP526 4-3 §4.3 String matching with finite automata](https://www.youtube.com/watch?v=OJmM61Jnf1I)\n",
    "* [Wikipedia page for Knuth–Morris–Pratt algorithm](http://web.archive.org/web/20230123223253/https://en.wikipedia.org/wiki/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm)\n",
    "* [Princeton KMP (Knuth Morris Pratt) Algorithm](https://www.youtube.com/watch?v=iZ93Unvxwtw)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
